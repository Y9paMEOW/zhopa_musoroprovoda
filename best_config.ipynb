{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "train = pd.read_parquet(\"train_data.pq\")\n",
    "sample = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "class ConfigurableRecommender:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.train = None\n",
    "        self.sample = None\n",
    "        self.prepared_data = {}\n",
    "        \n",
    "    def load_data(self, train_path, sample_path):\n",
    "        \"\"\"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
    "        self.train = pd.read_parquet(train_path)\n",
    "        self.sample = pd.read_csv(sample_path)\n",
    "        return self\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        \"\"\"–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å–æ–≥–ª–∞—Å–Ω–æ –∫–æ–Ω—Ñ–∏–≥—É\"\"\"\n",
    "        print(\"–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ...\")\n",
    "        \n",
    "        last_day = self.train[\"date\"].max()\n",
    "        self.prepared_data['last_day'] = last_day\n",
    "        k = self.config['time_window']['k']\n",
    "        \n",
    "        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞\n",
    "        for source_name, source_config in self.config['sources'].items():\n",
    "            if not source_config['enabled']:\n",
    "                continue\n",
    "                \n",
    "            if source_name == 'multiple_clicks_last_day':\n",
    "                self._prepare_multiple_clicks_last_day(last_day)\n",
    "                \n",
    "            elif source_name == 'last_day_clicks':\n",
    "                self._prepare_last_day_clicks(last_day)\n",
    "                \n",
    "            elif source_name == 'previous_days':\n",
    "                self._prepare_previous_days(last_day, k)\n",
    "                \n",
    "            elif source_name == 'global_popular':\n",
    "                self._prepare_global_popular(last_day)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _prepare_multiple_clicks_last_day(self, last_day):\n",
    "        \"\"\"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –∫–ª–∏–∫–∞–º –≤ –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–µ–Ω—å\"\"\"\n",
    "        last_day_data = self.train[self.train[\"date\"] == last_day]\n",
    "        user_multiple_clicks = {}\n",
    "        \n",
    "        last_day_counts = last_day_data.groupby([\"user_id\", \"item_id\"]).size()\n",
    "        for (user_id, item_id), count in last_day_counts.items():\n",
    "            if count > self.config['sources']['multiple_clicks_last_day']['min_clicks']:\n",
    "                if user_id not in user_multiple_clicks:\n",
    "                    user_multiple_clicks[user_id] = []\n",
    "                user_multiple_clicks[user_id].append(item_id)\n",
    "        \n",
    "        self.prepared_data['multiple_clicks_last_day'] = user_multiple_clicks\n",
    "        print(f\"  multiple_clicks_last_day: {len(user_multiple_clicks)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\")\n",
    "    \n",
    "    def _prepare_last_day_clicks(self, last_day):\n",
    "        \"\"\"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—Å–µ–º –∫–ª–∏–∫–∞–º –≤ –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–µ–Ω—å\"\"\"\n",
    "        last_day_data = self.train[self.train[\"date\"] == last_day]\n",
    "        user_last_clicks = last_day_data.groupby(\"user_id\")[\"item_id\"].apply(list).to_dict()\n",
    "        self.prepared_data['last_day_clicks'] = user_last_clicks\n",
    "        print(f\"  last_day_clicks: {len(user_last_clicks)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\")\n",
    "    \n",
    "    def _prepare_previous_days(self, last_day, k):\n",
    "        \"\"\"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ –ø—Ä–µ–¥—ã–¥—É—â–∏–º –¥–Ω—è–º\"\"\"\n",
    "        previous_days_candidates = {}\n",
    "        thresholds = self.config['sources']['previous_days']['thresholds']\n",
    "        \n",
    "        for day_offset in range(1, k + 1):\n",
    "            target_date = last_day - day_offset\n",
    "            day_data = self.train[self.train['date'] == target_date]\n",
    "            \n",
    "            if not day_data.empty:\n",
    "                threshold = thresholds[day_offset - 1] if day_offset <= len(thresholds) else thresholds[-1]\n",
    "                \n",
    "                day_counts = day_data.groupby(['user_id', 'item_id']).size().reset_index(name='count')\n",
    "                valid_items = day_counts[day_counts['count'] >= threshold]\n",
    "                \n",
    "                for _, row in valid_items.iterrows():\n",
    "                    user_id = row['user_id']\n",
    "                    item_id = row['item_id']\n",
    "                    \n",
    "                    if user_id not in previous_days_candidates:\n",
    "                        previous_days_candidates[user_id] = []\n",
    "                    previous_days_candidates[user_id].append(item_id)\n",
    "        \n",
    "        self.prepared_data['previous_days'] = previous_days_candidates\n",
    "        print(f\"  previous_days: {len(previous_days_candidates)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\")\n",
    "    \n",
    "    def _prepare_global_popular(self, last_day):\n",
    "        \"\"\"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≥–ª–æ–±–∞–ª—å–Ω–æ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤\"\"\"\n",
    "        if self.config['sources']['global_popular']['use_recent_days']:\n",
    "            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–Ω–µ–π –¥–ª—è –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏\n",
    "            recent_days = self.config['sources']['global_popular']['recent_days']\n",
    "            recent_data = self.train[self.train['date'] >= (last_day - recent_days)]\n",
    "            global_popular = recent_data['item_id'].value_counts().head(100).index.tolist()\n",
    "        else:\n",
    "            # –¢–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–µ–Ω—å\n",
    "            last_day_data = self.train[self.train[\"date\"] == last_day]\n",
    "            global_popular = last_day_data[\"item_id\"].value_counts().head(100).index.tolist()\n",
    "        \n",
    "        self.prepared_data['global_popular'] = global_popular\n",
    "        print(f\"  global_popular: {len(global_popular)} —Ç–æ–≤–∞—Ä–æ–≤\")\n",
    "    \n",
    "    def recommend_for_user(self, uid):\n",
    "        \"\"\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\"\"\"\n",
    "        recommendations = []\n",
    "        used_items = set()\n",
    "        \n",
    "        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞\n",
    "        for source_name in self.config['priority_order']:\n",
    "            source_config = self.config['sources'][source_name]\n",
    "            \n",
    "            if not source_config['enabled'] or len(recommendations) >= 20:\n",
    "                continue\n",
    "            \n",
    "            max_candidates = source_config['max_candidates']\n",
    "            candidates = self._get_candidates_from_source(uid, source_name)\n",
    "            \n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤, –ø–æ–∫–∞ –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω–µ–º –ª–∏–º–∏—Ç–∞\n",
    "            remaining_slots = min(20 - len(recommendations), max_candidates)\n",
    "            for item in candidates:\n",
    "                if item not in used_items and remaining_slots > 0:\n",
    "                    recommendations.append(item)\n",
    "                    used_items.add(item)\n",
    "                    remaining_slots -= 1\n",
    "                if len(recommendations) >= 20:\n",
    "                    break\n",
    "        \n",
    "        # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º 20 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π\n",
    "        if len(recommendations) < 20:\n",
    "            self._fill_remaining_slots(recommendations, used_items)\n",
    "        \n",
    "        return recommendations[:20]\n",
    "    \n",
    "    def _get_candidates_from_source(self, uid, source_name):\n",
    "        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞\"\"\"\n",
    "        if source_name == 'multiple_clicks_last_day':\n",
    "            return self.prepared_data.get('multiple_clicks_last_day', {}).get(uid, [])\n",
    "        \n",
    "        elif source_name == 'last_day_clicks':\n",
    "            return self.prepared_data.get('last_day_clicks', {}).get(uid, [])\n",
    "        \n",
    "        elif source_name == 'previous_days':\n",
    "            return self.prepared_data.get('previous_days', {}).get(uid, [])\n",
    "        \n",
    "        elif source_name == 'global_popular':\n",
    "            return self.prepared_data.get('global_popular', [])\n",
    "        \n",
    "        return []\n",
    "    \n",
    "    def _fill_remaining_slots(self, recommendations, used_items):\n",
    "        \"\"\"–ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è —Å–ª–æ—Ç–æ–≤ –≥–ª–æ–±–∞–ª—å–Ω–æ –ø–æ–ø—É–ª—è—Ä–Ω—ã–º–∏ —Ç–æ–≤–∞—Ä–∞–º–∏\"\"\"\n",
    "        global_popular = self.prepared_data.get('global_popular', [])\n",
    "        remaining_slots = 20 - len(recommendations)\n",
    "        \n",
    "        for item in global_popular:\n",
    "            if item not in used_items and remaining_slots > 0:\n",
    "                recommendations.append(item)\n",
    "                used_items.add(item)\n",
    "                remaining_slots -= 1\n",
    "            if remaining_slots <= 0:\n",
    "                break\n",
    "        \n",
    "        # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∞–º—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∏–∑ –≤—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "        if remaining_slots > 0:\n",
    "            all_popular = self.train['item_id'].value_counts().head(100).index.tolist()\n",
    "            for item in all_popular:\n",
    "                if item not in used_items and remaining_slots > 0:\n",
    "                    recommendations.append(item)\n",
    "                    used_items.add(item)\n",
    "                    remaining_slots -= 1\n",
    "                if remaining_slots <= 0:\n",
    "                    break\n",
    "    \n",
    "    def generate_submission(self, output_path):\n",
    "        \"\"\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–∞–±–º–∏—Ç–∞\"\"\"\n",
    "        print(\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π...\")\n",
    "        \n",
    "        test_users = self.sample[\"user_id\"].unique()\n",
    "        recs = []\n",
    "        \n",
    "        for uid in tqdm(test_users):\n",
    "            items = self.recommend_for_user(uid)\n",
    "            for item in items:\n",
    "                recs.append((uid, item))\n",
    "        \n",
    "        submission = pd.DataFrame(recs, columns=[\"user_id\", \"item_id\"])\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏\n",
    "        user_counts = submission['user_id'].value_counts()\n",
    "        if not (user_counts == 20).all():\n",
    "            print(\"–ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –±–µ–∑ 20 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π...\")\n",
    "            submission = self._fix_submission(submission)\n",
    "        \n",
    "        submission.to_csv(output_path, index=False)\n",
    "        print(f\"‚úÖ –°–∞–±–º–∏—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}\")\n",
    "        print(f\"   –í—Å–µ–≥–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {len(submission)}\")\n",
    "        print(f\"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {submission['user_id'].nunique()}\")\n",
    "        print(f\"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤: {submission['item_id'].nunique()}\")\n",
    "        \n",
    "        return submission\n",
    "    \n",
    "    def _fix_submission(self, submission):\n",
    "        \"\"\"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–∞–±–º–∏—Ç–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –±–µ–∑ 20 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π\"\"\"\n",
    "        global_popular = self.prepared_data.get('global_popular', [])\n",
    "        fixed_recs = []\n",
    "        \n",
    "        for uid in self.sample[\"user_id\"].unique():\n",
    "            user_items = submission[submission['user_id'] == uid]['item_id'].tolist()\n",
    "            \n",
    "            if len(user_items) < 20:\n",
    "                # –î–æ–±–∏—Ä–∞–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ –ø–æ–ø—É–ª—è—Ä–Ω—ã–º–∏\n",
    "                additional_items = [item for item in global_popular if item not in user_items]\n",
    "                user_items.extend(additional_items[:20 - len(user_items)])\n",
    "            \n",
    "            # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —Ä–æ–≤–Ω–æ 20\n",
    "            for item in user_items[:20]:\n",
    "                fixed_recs.append((uid, item))\n",
    "        \n",
    "        return pd.DataFrame(fixed_recs, columns=[\"user_id\", \"item_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # –ö–æ–Ω—Ñ–∏–≥ 3: –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π)\n",
    "CONFIG_BALANCED = {\n",
    "    'time_window': {\n",
    "        'k': 12\n",
    "    },\n",
    "    'sources': {\n",
    "        'multiple_clicks_last_day': {\n",
    "            'enabled': True,\n",
    "            'min_clicks': 1,\n",
    "            'max_candidates': 20\n",
    "        },\n",
    "        'last_day_clicks': {\n",
    "            'enabled': True,\n",
    "            'max_candidates': 20\n",
    "        },\n",
    "        'previous_days': {\n",
    "            'enabled': True,\n",
    "            'thresholds': [1]*11,\n",
    "            'max_candidates': 20\n",
    "        },\n",
    "        'global_popular': {\n",
    "            'enabled': True,\n",
    "            'use_recent_days': True,\n",
    "            'recent_days': 1,\n",
    "            'max_candidates': 20\n",
    "        }\n",
    "    },\n",
    "    'priority_order': [\n",
    "        'multiple_clicks_last_day',\n",
    "        'last_day_clicks',\n",
    "        'previous_days',\n",
    "        'global_popular'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ...\n",
      "  multiple_clicks_last_day: 0 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
      "  last_day_clicks: 98917 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
      "  previous_days: 962600 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
      "  global_popular: 100 —Ç–æ–≤–∞—Ä–æ–≤\n",
      "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293230/293230 [00:03<00:00, 73509.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –°–∞–±–º–∏—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: bilibert.csv\n",
      "   –í—Å–µ–≥–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: 5864600\n",
      "   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: 293230\n",
      "   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤: 135243\n",
      "\n",
      "üéØ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞:\n",
      "   - multiple_clicks_last_day: max_20\n",
      "   - last_day_clicks: max_20\n",
      "   - previous_days: max_20\n",
      "   - global_popular: max_20\n"
     ]
    }
   ],
   "source": [
    "# ==================== –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï ====================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # –í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–Ω—Ñ–∏–≥ –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
    "    CURRENT_CONFIG = CONFIG_BALANCED\n",
    "    \n",
    "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∑–∞–ø—É—Å–∫\n",
    "    recommender = ConfigurableRecommender(CURRENT_CONFIG)\n",
    "    recommender.load_data(\n",
    "        \"train_data.pq\",\n",
    "        \"sample_submission.csv\"\n",
    "    )\n",
    "    \n",
    "    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "    recommender.prepare_data()\n",
    "    \n",
    "    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∞–±–º–∏—Ç–∞\n",
    "    submission = recommender.generate_submission(\"bilibert.csv\")\n",
    "    \n",
    "    print(\"\\nüéØ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞:\")\n",
    "    for source in CURRENT_CONFIG['priority_order']:\n",
    "        if CURRENT_CONFIG['sources'][source]['enabled']:\n",
    "            config = CURRENT_CONFIG['sources'][source]\n",
    "            print(f\"   - {source}: max_{config['max_candidates']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_csv('da_bilo_x2.csv')\n",
    "f = list(submission['item_id'])\n",
    "s = list(check['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5407810\n"
     ]
    }
   ],
   "source": [
    "eq = 0\n",
    "for i in range(len(f)):\n",
    "    if f[i] == s[i]:\n",
    "        eq += 1\n",
    "print(eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5864600"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
